{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSQk-RGcyjcw",
        "outputId": "fc040206-4f5a-4c62-97af-2a67ee0e7594"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7J5gp9LzQzT"
      },
      "source": [
        "Nalaganje podatkovne zbirke slik uÅ¡es"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgzirW5cTTGm"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yHMwfeZ22GU"
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import cv2\n",
        "import keras\n",
        "\n",
        "TRAINING_CSV_FILE = '/content/drive/MyDrive/biomet/training_data.csv'\n",
        "TRAINING_IMAGE_DIR = '/content/drive/MyDrive/biomet/awe/data/ears/train/'\n",
        "WIDTH, HEIGHT = 480, 360\n",
        "\n",
        "f = open('/content/drive/MyDrive/biomet/awe/data/ears/annotations/detection/train.txt', 'r')\n",
        "\n",
        "train_targets = []\n",
        "train_images = []\n",
        "\n",
        "line = f.readline()\n",
        "while line:\n",
        "  data = line.split(' ')\n",
        "  img_path = data[0].split('/')[1]\n",
        "\n",
        "  train_image_fullpath = TRAINING_IMAGE_DIR + img_path\n",
        "  train_images.append(cv2.imread(train_image_fullpath, cv2.IMREAD_GRAYSCALE)/255)\n",
        "\n",
        "  xmin = round(int(data[1]) / WIDTH, 2)\n",
        "  ymin = round(int(data[2]) / HEIGHT, 2)\n",
        "  xmax = round((int(data[3]) + int(data[1])) / WIDTH, 2)\n",
        "  ymax = round((int(data[4]) + int(data[2])) / HEIGHT, 2)\n",
        "\n",
        "  train_targets.append([ xmin, ymin, xmax, ymax])\n",
        "\n",
        "  line = f.readline()\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_IMAGE_DIR = '/content/drive/MyDrive/biomet/awe/data/ears/test/'\n",
        "WIDTH, HEIGHT = 480, 360\n",
        "\n",
        "f = open('/content/drive/MyDrive/biomet/awe/data/ears/annotations/detection/test.txt', 'r')\n",
        "\n",
        "val_targets = []\n",
        "val_images = []\n",
        "\n",
        "line = f.readline()\n",
        "while line:\n",
        "  data = line.split(' ')\n",
        "  img_path = data[0].split('/')[1]\n",
        "\n",
        "  val_image_fullpath = VAL_IMAGE_DIR + img_path\n",
        "  val_images.append(cv2.imread(val_image_fullpath, cv2.IMREAD_GRAYSCALE)/255)\n",
        "\n",
        "  xmin = round(int(data[1]) / WIDTH, 2)\n",
        "  ymin = round(int(data[2]) / HEIGHT, 2)\n",
        "  xmax = round((int(data[3]) + int(data[1])) / WIDTH, 2)\n",
        "  ymax = round((int(data[4]) + int(data[2])) / HEIGHT, 2)\n",
        "\n",
        "  val_targets.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "  line = f.readline()\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "2sHJ9PFmp2Xh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "from PIL import Image \n",
        "from PIL.ImageDraw import Draw\n",
        "\n",
        "#create the common input layer\n",
        "input_shape = (HEIGHT, WIDTH, 1)\n",
        "input_layer = tf.keras.layers.Input(input_shape)\n",
        "labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
        "\n",
        "#create the base layers\n",
        "base_layers = layers.Conv2D(16, (3, 3), padding='same', activation='relu', name='bl_1')(input_layer)\n",
        "base_layers = layers.MaxPooling2D((2, 2), name='bl_2')(base_layers)\n",
        "base_layers = layers.Conv2D(32, (3, 3), padding='same', activation='relu', name='bl_3')(base_layers)\n",
        "base_layers = layers.MaxPooling2D((2, 2), name='bl_4')(base_layers)\n",
        "base_layers = layers.Conv2D(64, (3, 3), padding='same', activation='relu', name='bl_5')(base_layers)\n",
        "base_layers = layers.MaxPooling2D((2, 2), name='bl_6')(base_layers)\n",
        "base_layers = layers.Flatten(name='bl_7')(base_layers)\n",
        "\n",
        "#create the localiser branch\n",
        "locator_branch = layers.Dense(128, activation='relu', name='bb_1')(base_layers)\n",
        "locator_branch = layers.Dense(64, activation='relu', name='bb_2')(locator_branch)\n",
        "locator_branch = layers.Dense(32, activation='relu', name='bb_3')(locator_branch)\n",
        "locator_branch = layers.Dense(4, activation='sigmoid', name='bb_head')(locator_branch)"
      ],
      "metadata": {
        "id": "Grd7iZAbG60s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(input_layer, outputs=locator_branch)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "pJQW-yHDHA3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f52b9a-e853-47c5-ee81-4ce484eb418e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 360, 480, 1)]     0         \n",
            "                                                                 \n",
            " bl_1 (Conv2D)               (None, 360, 480, 16)      160       \n",
            "                                                                 \n",
            " bl_2 (MaxPooling2D)         (None, 180, 240, 16)      0         \n",
            "                                                                 \n",
            " bl_3 (Conv2D)               (None, 180, 240, 32)      4640      \n",
            "                                                                 \n",
            " bl_4 (MaxPooling2D)         (None, 90, 120, 32)       0         \n",
            "                                                                 \n",
            " bl_5 (Conv2D)               (None, 90, 120, 64)       18496     \n",
            "                                                                 \n",
            " bl_6 (MaxPooling2D)         (None, 45, 60, 64)        0         \n",
            "                                                                 \n",
            " bl_7 (Flatten)              (None, 172800)            0         \n",
            "                                                                 \n",
            " bb_1 (Dense)                (None, 128)               22118528  \n",
            "                                                                 \n",
            " bb_2 (Dense)                (None, 64)                8256      \n",
            "                                                                 \n",
            " bb_3 (Dense)                (None, 32)                2080      \n",
            "                                                                 \n",
            " bb_head (Dense)             (None, 4)                 132       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,152,292\n",
            "Trainable params: 22,152,292\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "val_images = np.array(val_images)\n",
        "train_targets = np.array(train_targets)\n",
        "val_targets = np.array(val_targets)"
      ],
      "metadata": {
        "id": "kmvFqGsEHEKd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INIT_LR = 1e-4\n",
        "NUM_EPOCHS = 55\n",
        "BATCH_SIZE = 15\n",
        "\n",
        "opt = tf.keras.optimizers.Adam()\n",
        "losses = {\"bb_head\":tf.keras.losses.MSE}\n",
        "\n",
        "model.compile(loss=tf.keras.losses.MSE, optimizer='Adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JfYfN4ttHJKu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_images, train_targets, validation_data=(val_images, val_targets), batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, shuffle=True, verbose=1)"
      ],
      "metadata": {
        "id": "hY1G5RdxHfpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe011f7d-a829-4628-9f09-b13a83a223b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/55\n",
            "57/57 [==============================] - 133s 2s/step - loss: 0.0363 - accuracy: 0.5576 - val_loss: 0.0337 - val_accuracy: 0.5694\n",
            "Epoch 2/55\n",
            "57/57 [==============================] - 132s 2s/step - loss: 0.0298 - accuracy: 0.6212 - val_loss: 0.0298 - val_accuracy: 0.6319\n",
            "Epoch 3/55\n",
            "57/57 [==============================] - 132s 2s/step - loss: 0.0236 - accuracy: 0.7153 - val_loss: 0.0235 - val_accuracy: 0.7292\n",
            "Epoch 4/55\n",
            "57/57 [==============================] - 133s 2s/step - loss: 0.0187 - accuracy: 0.7776 - val_loss: 0.0246 - val_accuracy: 0.6319\n",
            "Epoch 5/55\n",
            "57/57 [==============================] - 132s 2s/step - loss: 0.0160 - accuracy: 0.8059 - val_loss: 0.0252 - val_accuracy: 0.6910\n",
            "Epoch 6/55\n",
            "57/57 [==============================] - 132s 2s/step - loss: 0.0124 - accuracy: 0.8306 - val_loss: 0.0237 - val_accuracy: 0.7083\n",
            "Epoch 7/55\n",
            "57/57 [==============================] - 132s 2s/step - loss: 0.0108 - accuracy: 0.8471 - val_loss: 0.0222 - val_accuracy: 0.7326\n",
            "Epoch 8/55\n",
            "57/57 [==============================] - 132s 2s/step - loss: 0.0097 - accuracy: 0.8459 - val_loss: 0.0239 - val_accuracy: 0.7083\n",
            "Epoch 9/55\n",
            "57/57 [==============================] - 132s 2s/step - loss: 0.0089 - accuracy: 0.8553 - val_loss: 0.0232 - val_accuracy: 0.7222\n",
            "Epoch 10/55\n",
            "57/57 [==============================] - 131s 2s/step - loss: 0.0083 - accuracy: 0.8494 - val_loss: 0.0232 - val_accuracy: 0.7396\n",
            "Epoch 11/55\n",
            "57/57 [==============================] - 131s 2s/step - loss: 0.0079 - accuracy: 0.8706 - val_loss: 0.0240 - val_accuracy: 0.7118\n",
            "Epoch 12/55\n",
            "57/57 [==============================] - 131s 2s/step - loss: 0.0073 - accuracy: 0.8647 - val_loss: 0.0222 - val_accuracy: 0.7257\n",
            "Epoch 13/55\n",
            "57/57 [==============================] - 131s 2s/step - loss: 0.0070 - accuracy: 0.8753 - val_loss: 0.0236 - val_accuracy: 0.7222\n",
            "Epoch 14/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0068 - accuracy: 0.8859 - val_loss: 0.0235 - val_accuracy: 0.7222\n",
            "Epoch 15/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0067 - accuracy: 0.8847 - val_loss: 0.0232 - val_accuracy: 0.7326\n",
            "Epoch 16/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0066 - accuracy: 0.8871 - val_loss: 0.0245 - val_accuracy: 0.7118\n",
            "Epoch 17/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0068 - accuracy: 0.8800 - val_loss: 0.0227 - val_accuracy: 0.7292\n",
            "Epoch 18/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0066 - accuracy: 0.8859 - val_loss: 0.0233 - val_accuracy: 0.7118\n",
            "Epoch 19/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0065 - accuracy: 0.8976 - val_loss: 0.0225 - val_accuracy: 0.7222\n",
            "Epoch 20/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0063 - accuracy: 0.8953 - val_loss: 0.0234 - val_accuracy: 0.7257\n",
            "Epoch 21/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0063 - accuracy: 0.8835 - val_loss: 0.0237 - val_accuracy: 0.7188\n",
            "Epoch 22/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0062 - accuracy: 0.8941 - val_loss: 0.0222 - val_accuracy: 0.7326\n",
            "Epoch 23/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0062 - accuracy: 0.8894 - val_loss: 0.0225 - val_accuracy: 0.7326\n",
            "Epoch 24/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0062 - accuracy: 0.8918 - val_loss: 0.0233 - val_accuracy: 0.7153\n",
            "Epoch 25/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0063 - accuracy: 0.8871 - val_loss: 0.0227 - val_accuracy: 0.7188\n",
            "Epoch 26/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0062 - accuracy: 0.8918 - val_loss: 0.0227 - val_accuracy: 0.7396\n",
            "Epoch 27/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0061 - accuracy: 0.8918 - val_loss: 0.0225 - val_accuracy: 0.7222\n",
            "Epoch 28/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0061 - accuracy: 0.8976 - val_loss: 0.0223 - val_accuracy: 0.7292\n",
            "Epoch 29/55\n",
            "57/57 [==============================] - 130s 2s/step - loss: 0.0061 - accuracy: 0.8976 - val_loss: 0.0230 - val_accuracy: 0.7222\n",
            "Epoch 30/55\n",
            "29/57 [==============>...............] - ETA: 58s - loss: 0.0061 - accuracy: 0.8943 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.resize(cv2.imread('/content/drive/MyDrive/biomet/awe/data/ears/adam.jpg'), (width, height)) / 255\n",
        "pred = model.predict(np.array([img]))[0] * 1200 //1\n",
        "\n",
        "pred"
      ],
      "metadata": {
        "id": "nTUOsEOwoKTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['val_accuracy']"
      ],
      "metadata": {
        "id": "vnmdzBztrAPI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}